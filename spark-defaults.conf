spark.master spark://spark-master:7077
spark.eventLog.enabled true
spark.eventLog.dir file:///opt/bitnami/spark/logs
spark.history.fs.logDirectory file:///opt/bitnami/spark/logs
spark.deploy.recoveryMode NONE
spark.deploy.spreadOut false

# Spark Connect configuration
spark.connect.grpc.binding.port 15002
spark.connect.grpc.binding.host 0.0.0.0
spark.connect.grpc.arrow.enabled true

# Worker configuration - match your docker-compose setup
spark.executor.instances 2
spark.executor.cores 1
spark.executor.memory 1g
spark.driver.memory 1g

# Serialization settings - use Java serializer for better compatibility
spark.serializer org.apache.spark.serializer.JavaSerializer
spark.kryo.registrationRequired false

# Network settings
spark.network.timeout 800s
spark.executor.heartbeatInterval 60s

# Shuffle settings - reduce partitions for Spark Connect
spark.sql.shuffle.partitions 1
spark.sql.adaptive.enabled true
spark.sql.adaptive.coalescePartitions.enabled true

# Arrow settings
spark.sql.execution.arrow.pyspark.enabled true
spark.sql.execution.arrow.pyspark.fallback.enabled true

# Iceberg configuration
spark.sql.extensions org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.iceberg org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.type rest
spark.sql.catalog.iceberg.uri http://iceberg-rest:8181
spark.sql.catalog.iceberg.io-impl org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.iceberg.warehouse s3://iceberg/
spark.sql.catalog.iceberg.s3.endpoint http://minio:9000
spark.sql.catalog.iceberg.s3.access-key admin
spark.sql.catalog.iceberg.s3.secret-key password
spark.sql.catalog.iceberg.s3.region us-east-1
spark.sql.catalog.iceberg.s3.path-style-access true
spark.sql.catalog.iceberg.s3.ssl-enabled false
spark.sql.defaultCatalog iceberg
spark.sql.catalogImplementation in-memory

# Additional settings for Spark Connect + Iceberg compatibility
spark.sql.adaptive.skewJoin.enabled false
spark.sql.adaptive.localShuffleReader.enabled false
spark.sql.adaptive.optimizeSkewedJoin.enabled false

# S3A Filesystem configuration for direct S3/MinIO access
spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.access.key admin 
spark.hadoop.fs.s3a.secret.key password 
spark.hadoop.fs.s3a.endpoint http://minio:9000
spark.hadoop.fs.s3a.region us-east-1
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.connection.ssl.enabled false
spark.hadoop.fs.s3a.ssl.enabled false

# Logging configuration
spark.driver.extraJavaOptions -Dlog4j.configuration=file:///opt/bitnami/spark/conf/log4j.properties
spark.executor.extraJavaOptions -Dlog4j.configuration=file:///opt/bitnami/spark/conf/log4j.properties
spark.sql.streaming.checkpointLocation file:///opt/bitnami/spark/logs/checkpoints