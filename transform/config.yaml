gateways:
  local:
    connection:
      type: duckdb
      register_comments: True
      pre_ping: False
      pretty_sql: True
      extensions:
        - httpfs
        - iceberg
        - aws
      catalogs:
        iceberg:
          type: rest
          uri: 'http://localhost:8181'
          s3_region: {{ env_var('S3_REGION', 'us-east-1') }}
          s3_access_key_id: {{ env_var('S3_ACCESS_KEY', 'minioadmin') }}
          s3_secret_access_key: {{ env_var('S3_SECRET_KEY', 'minioadmin') }}
          s3_endpoint: {{ env_var('S3_ENDPOINT', 'http://localhost:9000') }}
          s3_url_style: 'path'
    state_connection:
      type: duckdb
      database: 'sqlmesh_state.db'
  
  spark:
    connection:
      type: spark
      config:
        # Use local mode since Iceberg JARs aren't available locally
        spark.master: local[*]
        # Basic Spark config (no Iceberg extensions)
        spark.sql.adaptive.enabled: true
        spark.sql.adaptive.coalescePartitions.enabled: true
    test_connection:
      type: spark
      config:
        # Use local mode for testing/validation - no cluster needed
        spark.master: local[*]
        # Basic Spark config for validation (no Iceberg extensions needed)
        spark.sql.adaptive.coalescePartitions.enabled: true
    state_connection:
      type: duckdb
      database: 'sqlmesh_spark_state.db'
  
  prod:
    connection:
      type: postgres
      host: {{ env_var('PG_HOST') }}
      port: {{ env_var('PG_PORT') }}
      user: {{ env_var('PG_USER') }}
      password: {{ env_var('PG_PASSWORD') }}
      database: postgres
      register_comments: True
      pre_ping: False
      pretty_sql: True
    state_connection:
      type: postgres
      host: {{ env_var('PG_HOST') }}
      port: {{ env_var('PG_PORT') }}
      user: {{ env_var('PG_USER') }}
      password: {{ env_var('PG_PASSWORD') }}
      database: postgres

default_gateway: local

model_defaults:
  dialect: duckdb

ignore_patterns:
  - "generator"