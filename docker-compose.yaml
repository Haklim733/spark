services:
  spark-master: 
    container_name: spark-master
    hostname: spark-master
    build: .
    networks:
      - spark-network
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_MASTER_PORT=7077
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WORKLOAD=master
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - SPARK_WEBUI_PORT=8080
      - SPARK_MASTER_LOG=/opt/bitnami/spark/logs/spark-master.out
      - SPARK_WORKER_LOG=/opt/bitnami/spark/logs/spark-worker.out
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # Spark 3.5 specific configurations
      - SPARK_VERSION=3.5.6
      - SPARK_MAJOR_VERSION=3.5
    healthcheck:
      test: ["CMD", "pgrep", "-f", "org.apache.spark.deploy.master.Master"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - ./src:/home/app/src
      - ./scripts:/home/app/scripts
      - ./spark-logs:/opt/bitnami/spark/logs
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    env_file:
      - .env.spark
    command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.master.Master
  spark-history:
    container_name: spark-history
    build: .
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - spark-network
    volumes:
      - ./src:/home/app/src
      - ./scripts:/home/app/scripts
      - ./spark-logs:/opt/bitnami/spark/logs
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    ports:
      - "18080:18080"
    environment:
      - SPARK_VERSION=3.5.6
      - SPARK_MAJOR_VERSION=3.5
    command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
  spark-worker:
    image: bitnami/spark:3.5.6
    build: .
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - spark-network
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WEBUI_PORT=8080
      - SPARK_MASTER_LOG=/opt/bitnami/spark/logs/spark-master.out
      - SPARK_WORKER_LOG=/opt/bitnami/spark/logs/spark-worker.out
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - SPARK_WORKER_LOG=/tmp/worker-logs/spark-worker.out
      - SPARK_EXECUTOR_LOGS_DIR=/tmp/worker-logs/executor
      # Spark 3.5 specific configurations
      - SPARK_VERSION=3.5.6
      - SPARK_MAJOR_VERSION=3.5
      # Spark 3.5 performance optimizations
      - SPARK_SQL_ADAPTIVE_ENABLED=true
      - SPARK_SQL_ADAPTIVE_COALESCE_PARTITIONS_ENABLED=true
      - SPARK_SQL_ADAPTIVE_SKEW_JOIN_ENABLED=true
      - SPARK_SQL_ADAPTIVE_LOCAL_SHUFFLE_READER_ENABLED=true
    healthcheck:
      test: ["CMD", "netstat", "-tuln", "|", "grep", ":8081"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 45s
    volumes:
      - ./scripts:/home/app/scripts
      - ./spark-logs:/opt/bitnami/spark/logs
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./logs/workers/worker.out:/opt/bitnami/spark/logs/spark-worker.out
      - ./logs/worker/executor:/opt/bitnami/spark/logs/executor
      # Mount events directory separately
    command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    scale: 2  # This creates 2 worker instances
  rest:
    image: apache/iceberg-rest-fixture
    container_name: spark-rest
    networks:
      - spark-network
    depends_on:
      - minio
      - postgres
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_S3_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://data/warehouse
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
      # PostgreSQL connection for Iceberg REST API
      - CATALOG_DB_HOST=postgres
      - CATALOG_DB_PORT=5432
      - CATALOG_DB_NAME=iceberg
      - CATALOG_DB_USER=iceberg
      - CATALOG_DB_PASSWORD=iceberg
  minio:
    image: minio/minio
    container_name: spark-minio
    networks:
      spark-network:
        aliases:
          - data.minio # important for spark to write to minio <bucket>.minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]
  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: spark-mc
    networks:
      - spark-network
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/data;
      /usr/bin/mc mb minio/data;
      /usr/bin/mc anonymous set public minio/data;
      set +o history;
      tail -f /dev/null"
  postgres:
    image: postgres:16-alpine
    container_name: spark-postgres
    networks:
      - spark-network
    environment:
      - POSTGRES_DB=iceberg
      - POSTGRES_USER=iceberg
      - POSTGRES_PASSWORD=iceberg
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U iceberg -d iceberg"]
      interval: 10s
      timeout: 5s
      retries: 5
volumes:
  spark-logs:
  postgres_data:
networks:
  spark-network:
    driver: bridge
